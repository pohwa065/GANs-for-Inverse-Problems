import torch
import torch.nn as nn
import torch.nn.functional as F # For F.relu, F.max_pool2d
import torch.fft
import numpy as np
import math

# --- Utility and Helper Functions (create_grid, propagate_fresnel_pytorch) ---
# These are assumed to be the same as in the previous polarized examples.
# For brevity, I'll include them collapsed here. If you need them expanded, let me know.

def create_grid(H, W, dx_m, device='cpu'):
    if isinstance(dx_m, float): dy_m, dx_m_val = dx_m, dx_m
    else: dy_m, dx_m_val = dx_m
    x = torch.arange(-W // 2, W // 2, device=device) * dx_m_val
    y = torch.arange(-H // 2, H // 2, device=device) * dy_m
    y_coords, x_coords = torch.meshgrid(y, x, indexing='ij')
    fx_cycles_sample = torch.fft.fftfreq(W, d=1.0, device=device)
    fy_cycles_sample = torch.fft.fftfreq(H, d=1.0, device=device)
    fy_coords_mesh, fx_coords_mesh = torch.meshgrid(fy_cycles_sample, fx_cycles_sample, indexing='ij')
    fy_coords_phys_mesh = fy_coords_mesh / dy_m
    fx_coords_phys_mesh = fx_coords_mesh / dx_m_val
    return x_coords, y_coords, fx_coords_phys_mesh, fy_coords_phys_mesh

def propagate_fresnel_pytorch(input_field_n1hw, dx_m, dist_m, wavelength_m):
    N, C, H, W = input_field_n1hw.shape
    device = input_field_n1hw.device
    if C != 1: raise ValueError("propagate_fresnel_pytorch expects C=1")
    input_field = input_field_n1hw.squeeze(1)
    if isinstance(dx_m, float): dy_m_in, dx_m_in = dx_m, dx_m
    else: dy_m_in, dx_m_in = dx_m
    x_coords_in, y_coords_in, fx_coords_prop, fy_coords_prop = create_grid(H, W, (dy_m_in, dx_m_in), device=device)
    quad_phase_factor_in = torch.exp(1j * torch.pi / (wavelength_m * dist_m) * (x_coords_in**2 + y_coords_in**2)).unsqueeze(0)
    U_prime = input_field * quad_phase_factor_in
    G = torch.fft.fft2(U_prime, norm='ortho')
    propagator_freq = torch.exp(1j * torch.pi * wavelength_m * dist_m * (fx_coords_prop**2 + fy_coords_prop**2)).unsqueeze(0)
    Result_freq = G * propagator_freq
    U_sensor_scaled = torch.fft.ifft2(Result_freq, norm='ortho')
    final_scaling_phase = torch.exp(1j * 2 * torch.pi * dist_m / wavelength_m) / (1j * wavelength_m * dist_m)
    output_field = U_sensor_scaled * final_scaling_phase
    return output_field.unsqueeze(1)

# --- Optical System Module (Freeform Polarized) ---
class FreeformPhasePlateOptimizerPolarizedPT(nn.Module):
    def __init__(self, params):
        super().__init__()
        self.params = params
        self.device = params.get('device', 'cuda' if torch.cuda.is_available() else 'cpu')
        self.wavelength_m = params['wavelength_m']
        self.pupil_diameter_m = params['pupil_diameter_m']
        self.propagation_distance_m = params['propagation_distance_m']
        self.grid_size_h = params['grid_size_h']
        self.grid_size_w = params['grid_size_w']
        self.pupil_sample_dy_m = self.pupil_diameter_m / self.grid_size_h
        self.pupil_sample_dx_m = self.pupil_diameter_m / self.grid_size_w

        initial_phase = torch.zeros((self.grid_size_h, self.grid_size_w), device=self.device)
        self.learnable_phase_hw = nn.Parameter(initial_phase)

        y_coords = torch.linspace(-self.grid_size_h // 2, self.grid_size_h // 2 -1, self.grid_size_h, device=self.device) * self.pupil_sample_dy_m
        x_coords = torch.linspace(-self.grid_size_w // 2, self.grid_size_w // 2 -1, self.grid_size_w, device=self.device) * self.pupil_sample_dx_m
        Y, X = torch.meshgrid(y_coords, x_coords, indexing='ij')
        R_sq = X**2 + Y**2
        pupil_radius_sq = (self.pupil_diameter_m / 2)**2
        aperture_mask = (R_sq <= pupil_radius_sq).float()
        self.register_buffer('aperture_mask_hw', aperture_mask)

    def forward(self, input_E_complex_n2hw):
        if input_E_complex_n2hw.shape[1] != 2:
            raise ValueError("Input E-field must have 2 channels (Ex, Ey).")
        Ex_pupil_n1hw = input_E_complex_n2hw[:, 0:1, :, :]
        Ey_pupil_n1hw = input_E_complex_n2hw[:, 1:2, :, :]
        phase_shift_11hw = self.learnable_phase_hw.unsqueeze(0).unsqueeze(0)
        Ex_pupil_out_n1hw = Ex_pupil_n1hw * torch.exp(1j * phase_shift_11hw)
        Ey_pupil_out_n1hw = Ey_pupil_n1hw * torch.exp(1j * phase_shift_11hw)
        aperture_mask_11hw = self.aperture_mask_hw.unsqueeze(0).unsqueeze(0)
        Ex_apertured_n1hw = Ex_pupil_out_n1hw * aperture_mask_11hw
        Ey_apertured_n1hw = Ey_pupil_out_n1hw * aperture_mask_11hw
        dx_m_tuple = (self.pupil_sample_dy_m, self.pupil_sample_dx_m)
        Ex_sensor_n1hw = propagate_fresnel_pytorch(Ex_apertured_n1hw, dx_m_tuple, self.propagation_distance_m, self.wavelength_m)
        Ey_sensor_n1hw = propagate_fresnel_pytorch(Ey_apertured_n1hw, dx_m_tuple, self.propagation_distance_m, self.wavelength_m)
        psf_Ex_n1hw = torch.abs(Ex_sensor_n1hw)**2
        psf_Ey_n1hw = torch.abs(Ey_sensor_n1hw)**2
        total_psf_n1hw = psf_Ex_n1hw + psf_Ey_n1hw
        return total_psf_n1hw

# --- Simple CNN Classifier for PSFs ---
class PSFClassifierCNN(nn.Module):
    def __init__(self, input_h, input_w, num_classes):
        super().__init__()
        self.input_h = input_h
        self.input_w = input_w
        self.num_classes = num_classes

        # Convolutional layers
        # Input PSF is (N, 1, H, W)
        self.conv1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=5, stride=1, padding=2) # (N, 16, H, W)
        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2) # (N, 16, H/2, W/2)
        
        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1) # (N, 32, H/2, W/2)
        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2) # (N, 32, H/4, W/4)

        self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1) # (N, 64, H/4, W/4)
        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2) # (N, 64, H/8, W/8)

        # Calculate the flattened size after convolutions and pooling
        # This depends on input_h, input_w and the conv/pool architecture
        # For H=64, W=64: H/8 = 8, W/8 = 8. So, 64 * 8 * 8
        # For H=32, W=32: H/8 = 4, W/8 = 4. So, 64 * 4 * 4
        self.fc_input_h = input_h // 8
        self.fc_input_w = input_w // 8
        self.flattened_size = 64 * self.fc_input_h * self.fc_input_w

        # Fully connected layers
        self.fc1 = nn.Linear(self.flattened_size, 128)
        self.fc2 = nn.Linear(128, num_classes) # Output layer (logits)

    def forward(self, psf_n1hw):
        # psf_n1hw has shape (N, 1, H, W)
        x = F.relu(self.conv1(psf_n1hw))
        x = self.pool1(x)
        
        x = F.relu(self.conv2(x))
        x = self.pool2(x)

        x = F.relu(self.conv3(x))
        x = self.pool3(x)
        
        x = x.view(-1, self.flattened_size) # Flatten the tensor
        
        x = F.relu(self.fc1(x))
        # No activation on the last layer as CrossEntropyLoss expects logits
        logits = self.fc2(x) # (N, num_classes)
        return logits

# --- End-to-End Model combining Optics and Classifier ---
class EndToEndOpticalClassifierPT(nn.Module):
    def __init__(self, optical_params, cnn_input_h, cnn_input_w, num_classes):
        super().__init__()
        # Instantiate the optical frontend (Freeform version)
        self.optical_system = FreeformPhasePlateOptimizerPolarizedPT(optical_params)
        
        # Instantiate the CNN classifier
        # The input H, W for CNN is the H, W of the PSF generated by the optical system
        self.classifier = PSFClassifierCNN(input_h=cnn_input_h, input_w=cnn_input_w, num_classes=num_classes)

    def forward(self, input_E_complex_n2hw):
        # 1. Pass E-field through the optical system to get PSF
        # psf_n1hw has shape (N, 1, H_psf, W_psf)
        psf_n1hw = self.optical_system(input_E_complex_n2hw)
        
        # 2. Pass the PSF through the classifier
        # logits has shape (N, num_classes)
        logits = self.classifier(psf_n1hw)
        
        return logits

# --- Main Training Loop Example ---
if __name__ == '__main__':
    print("PyTorch End-to-End Freeform Optics + CNN Classifier Prototyping")

    NUM_CLASSES = 3 # Example: 3 different classes of input E-fields

    # --- Define parameters ---
    # Optical parameters are nested for clarity
    optical_params = {
        'wavelength_m': 550e-9,
        'pupil_diameter_m': 5e-3,
        'propagation_distance_m': 50e-3,
        'grid_size_h': 32, # PSF height, also CNN input height
        'grid_size_w': 32, # PSF width, also CNN input width
        'device': 'cuda' if torch.cuda.is_available() else 'cpu',
    }
    
    # Training parameters
    training_params = {
        'learning_rate': 1e-4, # May need careful tuning for joint optimization
        'num_epochs': 100,     # Increase for real training
        'batch_size': 8,       # Adjust based on GPU memory
        'num_classes': NUM_CLASSES
    }
    print(f"Using device: {optical_params['device']}")

    # Instantiate the end-to-end model
    # The CNN input H, W are the optical system's grid_size_h, grid_size_w
    e2e_model = EndToEndOpticalClassifierPT(
        optical_params=optical_params,
        cnn_input_h=optical_params['grid_size_h'],
        cnn_input_w=optical_params['grid_size_w'],
        num_classes=training_params['num_classes']
    ).to(optical_params['device'])

    # Optimizer - will optimize parameters of BOTH optical_system and classifier
    optimizer = torch.optim.Adam(e2e_model.parameters(), lr=training_params['learning_rate'])
    
    # Loss function for classification
    criterion = nn.CrossEntropyLoss()

    # --- Example: Create dummy input E-field data and labels ---
    # For a real scenario, load your actual E-field data and corresponding class labels
    # Each class might have a characteristic E-field (e.g., different wavefronts, amplitudes)
    
    all_dummy_E_fields = []
    all_dummy_labels = []
    
    pupil_sample_dy = optical_params['pupil_diameter_m'] / optical_params['grid_size_h']
    pupil_sample_dx = optical_params['pupil_diameter_m'] / optical_params['grid_size_w']
    y_p = (torch.arange(optical_params['grid_size_h'], device=optical_params['device']) - optical_params['grid_size_h'] // 2) * pupil_sample_dy
    x_p = (torch.arange(optical_params['grid_size_w'], device=optical_params['device']) - optical_params['grid_size_w'] // 2) * pupil_sample_dx
    Y_p, X_p = torch.meshgrid(y_p, x_p, indexing='ij')

    for class_idx in range(training_params['num_classes']):
        for _ in range(training_params['batch_size'] * 2): # Create more data than one batch
            # Create slightly different E-fields for each class (very simplistic example)
            # Ex component
            w0_ex = (optical_params['pupil_diameter_m'] / 2) * (0.3 + class_idx * 0.05 + np.random.rand()*0.02)
            amp_ex = torch.exp(-(X_p**2 + Y_p**2) / (w0_ex**2))
            phase_ex = (X_p / (optical_params['pupil_diameter_m']/2)) * (torch.pi * 0.1 * class_idx) # Class-dependent phase ramp
            E_complex_ex = amp_ex * torch.exp(1j * phase_ex)

            # Ey component
            w0_ey = (optical_params['pupil_diameter_m'] / 2) * (0.35 + class_idx * 0.05 + np.random.rand()*0.02)
            amp_ey = torch.exp(-(X_p**2 + Y_p**2) / (w0_ey**2))
            phase_ey = (Y_p / (optical_params['pupil_diameter_m']/2)) * (torch.pi * 0.1 * class_idx)
            E_complex_ey = amp_ey * torch.exp(1j * phase_ey)
            
            single_E_field_2hw = torch.stack([E_complex_ex, E_complex_ey], dim=0) # (2, H, W)
            all_dummy_E_fields.append(single_E_field_2hw)
            all_dummy_labels.append(torch.tensor(class_idx, dtype=torch.long, device=optical_params['device']))

    # Convert list of tensors to a single batch tensor for E-fields and labels
    dataset_E_fields_n2hw = torch.stack(all_dummy_E_fields).to(optical_params['device'])
    dataset_labels_n = torch.stack(all_dummy_labels).to(optical_params['device'])
    
    print(f"Total dataset size: {dataset_E_fields_n2hw.shape[0]}")
    print(f"Input E-field batch shape for training: (Batch, 2, {optical_params['grid_size_h']}, {optical_params['grid_size_w']})")
    print(f"Labels shape for training: (Batch,)")

    # --- Training loop ---
    for epoch in range(training_params['num_epochs']):
        e2e_model.train() # Set model to training mode
        
        # Simple batching from the dummy dataset
        permutation = torch.randperm(dataset_E_fields_n2hw.size(0))
        for i in range(0, dataset_E_fields_n2hw.size(0), training_params['batch_size']):
            optimizer.zero_grad()
            
            indices = permutation[i : i + training_params['batch_size']]
            batch_E_fields = dataset_E_fields_n2hw[indices]
            batch_labels = dataset_labels_n[indices]

            if batch_E_fields.shape[0] == 0: continue # Skip if last batch is empty

            # Forward pass through the end-to-end model
            # output_logits will have shape (N_batch, num_classes)
            output_logits = e2e_model(batch_E_fields)
            
            # Calculate classification loss
            loss = criterion(output_logits, batch_labels)
            
            # Backward pass and optimization
            loss.backward()
            optimizer.step()
        
        # Print progress (e.g., loss and accuracy on a validation set if available)
        if (epoch + 1) % 10 == 0 or epoch == 0:
            print(f"Epoch [{epoch+1}/{training_params['num_epochs']}], Loss: {loss.item():.4f}")
            # For accuracy, you would typically run on a validation set:
            e2e_model.eval()
            with torch.no_grad():
                # Example: use the same training data for quick eval (not good practice)
                val_logits = e2e_model(dataset_E_fields_n2hw[:training_params['batch_size']*2]) # Eval on a subset
                val_labels_subset = dataset_labels_n[:training_params['batch_size']*2]
                _, predicted_classes = torch.max(val_logits, 1)
                correct_predictions = (predicted_classes == val_labels_subset).sum().item()
                accuracy = correct_predictions / val_labels_subset.size(0)
                print(f"  Approx. Training Accuracy (on subset): {accuracy*100:.2f}%")


    print("Training finished.")
    # After training, e2e_model.optical_system.learnable_phase_hw contains the optimized phase.
    # e2e_model.classifier contains the trained CNN weights.

    # Example: Visualize the learned phase plate
    # import matplotlib.pyplot as plt
    # learned_phase = e2e_model.optical_system.learnable_phase_hw.data.cpu().numpy()
    # plt.imshow(learned_phase, cmap='twilight_shifted')
    # plt.colorbar(label="Learned Phase (radians)")
    # plt.title("Optimized Freeform Phase Plate for Classification")
    # plt.show()


